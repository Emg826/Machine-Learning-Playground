{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to OpenAI Gym -- the Mountain Car Example -- 20191004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI's `gym` module provides users with a wide variety of environments (e.g., the video game world) in which an agent (e.g., a neural network) must learn to control some object therein. For reinforcement learning agents, the agents learn within a conceptual framework know as a **Markov decision process**.\n",
    "\n",
    "This process discretizes time (which is what computers already do) into time steps. At each time step the agent observes the state of environment, takes an action based on that observation, and notes the immediate results/reward from taking that action. In a Markov Decision Process, each of these steps in the next-most time step is a random variable, i.e., before it is \"sampled\"/observed/selected/received, the agent only knows rough probabilities of the outcome of the \"sample.\" Therefore, these steps (observe, act, note results) are a really just a sequence random variables of the form: $\\textrm{state}_0$,$\\textrm{action}_0$,$\\textrm{reward}_1$,$\\textrm{state}_1$,$\\textrm{action}_1$,$\\textrm{reward}_2$,...,$\\textrm{state}_t$. In this sense, the sequence is a \"process,\" a stochastic one specifically, and one over which the agent can exert some degree of  control.\n",
    "\n",
    "The agent exerts control over the process by making decision: what $\\textrm{action}_t$ should be. The notion of \"should\" necessitates an objective. In reinforcement learning, the objective is to maximize the reward. Given that most processes that are worth learning have multiple steps, more accurately, the objective is to maximize the sum of the rewards from here on out: the cumulative reward. However, given that maximizing cumulative reward necessarily involves anticipating the results of future actions and given that the results of future actions are random, there is no way for the agent to \"know\" the cumulative reward and thereby maximize it. Instead, the agent tries to do the next best thing: maximize the *expected* cumulative reward (*expected* as in *expected value*). For mathematical underpinning purposes (proofs of algorithmic convergence), and to model immediate rewards beinging preferred to future rewards (assuming the same reward), the expected cumulative reward is often present-value-discounted. Mathematically, this can all be written:\n",
    "$\\sum_{i=0}^{end} \\gamma^i E[r_{i+1} | s_i, a_i]$, where $\\gamma$ is the PV discount factor $\\in [0,1).$ \n",
    "\n",
    "Oh, one more thing about MDPs: the action $a_i$ is decided upon by considering *only* the current state $s_i$, hence why there was no $s_{i-1}$ in the above expected value. This is what is known as the Markov assumption, which, more generally, can be stated as: the past provides no additional information beyond that which is provided by present. Now, oftentimes, this assumption cannot strictly be met by considering the only the environment at a single moment in time. Therefore, oftentimes, the \"state at time $t$\" is often relaxed to be include some (but not all) prior moments' details.\n",
    "\n",
    "Reinforcement learning's place in all of this is in providing the agent with a set of instructions, an algorithm, by which it can learn to maximize the PV discounted expected cumulative reward. There are many different reinforcement learning algorithms out there; check out the \"Reinforcement Learning\" Wikipedia page for a great start. Since this is an OpenAI Gym walkthrough, we can stop at this explaination of each piece. And, finally, we can get to the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Environments Are Available?\n",
    "\n",
    "OpenAI `gym` *does not* provide agents. This is purposeful; `gym`'s mission statement can be said to be: to provide reinforcement learning researchers with a set of easy-to-use, standardized environments *so as to make developing reinforcement learning algorithms easier.* The environments are easy-to-use and standardized in the sense that they (oftentimes simple video games) don't require super powerful hardware, and they also tend to only require a few lines of code, as we'll see shortly. For now, though, let's see what environments `gym` contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 256 --- Acrobot\n",
      "2 of 256 --- AirRaid\n",
      "3 of 256 --- AirRaidDeterministic\n",
      "4 of 256 --- AirRaidNoFrameskip\n",
      "5 of 256 --- Alien\n",
      "6 of 256 --- AlienDeterministic\n",
      "7 of 256 --- AlienNoFrameskip\n",
      "8 of 256 --- Amidar\n",
      "9 of 256 --- AmidarDeterministic\n",
      "10 of 256 --- AmidarNoFrameskip\n",
      "11 of 256 --- Ant\n",
      "12 of 256 --- Assault\n",
      "13 of 256 --- AssaultDeterministic\n",
      "14 of 256 --- AssaultNoFrameskip\n",
      "15 of 256 --- Asterix\n",
      "16 of 256 --- AsterixDeterministic\n",
      "17 of 256 --- AsterixNoFrameskip\n",
      "18 of 256 --- Asteroids\n",
      "19 of 256 --- AsteroidsDeterministic\n",
      "20 of 256 --- AsteroidsNoFrameskip\n",
      "21 of 256 --- Atlantis\n",
      "22 of 256 --- AtlantisDeterministic\n",
      "23 of 256 --- AtlantisNoFrameskip\n",
      "24 of 256 --- BankHeist\n",
      "25 of 256 --- BankHeistDeterministic\n",
      "26 of 256 --- BankHeistNoFrameskip\n",
      "27 of 256 --- BattleZone\n",
      "28 of 256 --- BattleZoneDeterministic\n",
      "29 of 256 --- BattleZoneNoFrameskip\n",
      "30 of 256 --- BeamRider\n",
      "31 of 256 --- BeamRiderDeterministic\n",
      "32 of 256 --- BeamRiderNoFrameskip\n",
      "33 of 256 --- Berzerk\n",
      "34 of 256 --- BerzerkDeterministic\n",
      "35 of 256 --- BerzerkNoFrameskip\n",
      "36 of 256 --- BipedalWalker\n",
      "37 of 256 --- BipedalWalkerHardcore\n",
      "38 of 256 --- Blackjack\n",
      "39 of 256 --- Bowling\n",
      "40 of 256 --- BowlingDeterministic\n",
      "41 of 256 --- BowlingNoFrameskip\n",
      "42 of 256 --- Boxing\n",
      "43 of 256 --- BoxingDeterministic\n",
      "44 of 256 --- BoxingNoFrameskip\n",
      "45 of 256 --- Breakout\n",
      "46 of 256 --- BreakoutDeterministic\n",
      "47 of 256 --- BreakoutNoFrameskip\n",
      "48 of 256 --- CarRacing\n",
      "49 of 256 --- Carnival\n",
      "50 of 256 --- CarnivalDeterministic\n",
      "51 of 256 --- CarnivalNoFrameskip\n",
      "52 of 256 --- CartPole\n",
      "53 of 256 --- Centipede\n",
      "54 of 256 --- CentipedeDeterministic\n",
      "55 of 256 --- CentipedeNoFrameskip\n",
      "56 of 256 --- ChopperCommand\n",
      "57 of 256 --- ChopperCommandDeterministic\n",
      "58 of 256 --- ChopperCommandNoFrameskip\n",
      "59 of 256 --- CliffWalking\n",
      "60 of 256 --- Copy\n",
      "61 of 256 --- CrazyClimber\n",
      "62 of 256 --- CrazyClimberDeterministic\n",
      "63 of 256 --- CrazyClimberNoFrameskip\n",
      "64 of 256 --- CubeCrash\n",
      "65 of 256 --- CubeCrashScreenBecomesBlack\n",
      "66 of 256 --- CubeCrashSparse\n",
      "67 of 256 --- DemonAttack\n",
      "68 of 256 --- DemonAttackDeterministic\n",
      "69 of 256 --- DemonAttackNoFrameskip\n",
      "70 of 256 --- DoubleDunk\n",
      "71 of 256 --- DoubleDunkDeterministic\n",
      "72 of 256 --- DoubleDunkNoFrameskip\n",
      "73 of 256 --- DuplicatedInput\n",
      "74 of 256 --- ElevatorAction\n",
      "75 of 256 --- ElevatorActionDeterministic\n",
      "76 of 256 --- ElevatorActionNoFrameskip\n",
      "77 of 256 --- Enduro\n",
      "78 of 256 --- EnduroDeterministic\n",
      "79 of 256 --- EnduroNoFrameskip\n",
      "80 of 256 --- FetchPickAndPlace\n",
      "81 of 256 --- FetchPickAndPlaceDense\n",
      "82 of 256 --- FetchPush\n",
      "83 of 256 --- FetchPushDense\n",
      "84 of 256 --- FetchReach\n",
      "85 of 256 --- FetchReachDense\n",
      "86 of 256 --- FetchSlide\n",
      "87 of 256 --- FetchSlideDense\n",
      "88 of 256 --- FishingDerby\n",
      "89 of 256 --- FishingDerbyDeterministic\n",
      "90 of 256 --- FishingDerbyNoFrameskip\n",
      "91 of 256 --- Freeway\n",
      "92 of 256 --- FreewayDeterministic\n",
      "93 of 256 --- FreewayNoFrameskip\n",
      "94 of 256 --- Frostbite\n",
      "95 of 256 --- FrostbiteDeterministic\n",
      "96 of 256 --- FrostbiteNoFrameskip\n",
      "97 of 256 --- FrozenLake\n",
      "98 of 256 --- FrozenLake8x8\n",
      "99 of 256 --- Gopher\n",
      "100 of 256 --- GopherDeterministic\n",
      "101 of 256 --- GopherNoFrameskip\n",
      "102 of 256 --- Gravitar\n",
      "103 of 256 --- GravitarDeterministic\n",
      "104 of 256 --- GravitarNoFrameskip\n",
      "105 of 256 --- GuessingGame\n",
      "106 of 256 --- HalfCheetah\n",
      "107 of 256 --- HandManipulateBlock\n",
      "108 of 256 --- HandManipulateBlockDense\n",
      "109 of 256 --- HandManipulateBlockFull\n",
      "110 of 256 --- HandManipulateBlockFullDense\n",
      "111 of 256 --- HandManipulateBlockRotateParallel\n",
      "112 of 256 --- HandManipulateBlockRotateParallelDense\n",
      "113 of 256 --- HandManipulateBlockRotateXYZ\n",
      "114 of 256 --- HandManipulateBlockRotateXYZDense\n",
      "115 of 256 --- HandManipulateBlockRotateZ\n",
      "116 of 256 --- HandManipulateBlockRotateZDense\n",
      "117 of 256 --- HandManipulateEgg\n",
      "118 of 256 --- HandManipulateEggDense\n",
      "119 of 256 --- HandManipulateEggFull\n",
      "120 of 256 --- HandManipulateEggFullDense\n",
      "121 of 256 --- HandManipulateEggRotate\n",
      "122 of 256 --- HandManipulateEggRotateDense\n",
      "123 of 256 --- HandManipulatePen\n",
      "124 of 256 --- HandManipulatePenDense\n",
      "125 of 256 --- HandManipulatePenFull\n",
      "126 of 256 --- HandManipulatePenFullDense\n",
      "127 of 256 --- HandManipulatePenRotate\n",
      "128 of 256 --- HandManipulatePenRotateDense\n",
      "129 of 256 --- HandReach\n",
      "130 of 256 --- HandReachDense\n",
      "131 of 256 --- Hero\n",
      "132 of 256 --- HeroDeterministic\n",
      "133 of 256 --- HeroNoFrameskip\n",
      "134 of 256 --- Hopper\n",
      "135 of 256 --- HotterColder\n",
      "136 of 256 --- Humanoid\n",
      "137 of 256 --- HumanoidStandup\n",
      "138 of 256 --- IceHockey\n",
      "139 of 256 --- IceHockeyDeterministic\n",
      "140 of 256 --- IceHockeyNoFrameskip\n",
      "141 of 256 --- InvertedDoublePendulum\n",
      "142 of 256 --- InvertedPendulum\n",
      "143 of 256 --- Jamesbond\n",
      "144 of 256 --- JamesbondDeterministic\n",
      "145 of 256 --- JamesbondNoFrameskip\n",
      "146 of 256 --- JourneyEscape\n",
      "147 of 256 --- JourneyEscapeDeterministic\n",
      "148 of 256 --- JourneyEscapeNoFrameskip\n",
      "149 of 256 --- Kangaroo\n",
      "150 of 256 --- KangarooDeterministic\n",
      "151 of 256 --- KangarooNoFrameskip\n",
      "152 of 256 --- KellyCoinflip\n",
      "153 of 256 --- KellyCoinflipGeneralized\n",
      "154 of 256 --- Krull\n",
      "155 of 256 --- KrullDeterministic\n",
      "156 of 256 --- KrullNoFrameskip\n",
      "157 of 256 --- KungFuMaster\n",
      "158 of 256 --- KungFuMasterDeterministic\n",
      "159 of 256 --- KungFuMasterNoFrameskip\n",
      "160 of 256 --- LunarLander\n",
      "161 of 256 --- LunarLanderContinuous\n",
      "162 of 256 --- MemorizeDigits\n",
      "163 of 256 --- MontezumaRevenge\n",
      "164 of 256 --- MontezumaRevengeDeterministic\n",
      "165 of 256 --- MontezumaRevengeNoFrameskip\n",
      "166 of 256 --- MountainCar\n",
      "167 of 256 --- MountainCarContinuous\n",
      "168 of 256 --- MsPacman\n",
      "169 of 256 --- MsPacmanDeterministic\n",
      "170 of 256 --- MsPacmanNoFrameskip\n",
      "171 of 256 --- NChain\n",
      "172 of 256 --- NameThisGame\n",
      "173 of 256 --- NameThisGameDeterministic\n",
      "174 of 256 --- NameThisGameNoFrameskip\n",
      "175 of 256 --- Pendulum\n",
      "176 of 256 --- Phoenix\n",
      "177 of 256 --- PhoenixDeterministic\n",
      "178 of 256 --- PhoenixNoFrameskip\n",
      "179 of 256 --- Pitfall\n",
      "180 of 256 --- PitfallDeterministic\n",
      "181 of 256 --- PitfallNoFrameskip\n",
      "182 of 256 --- Pong\n",
      "183 of 256 --- PongDeterministic\n",
      "184 of 256 --- PongNoFrameskip\n",
      "185 of 256 --- Pooyan\n",
      "186 of 256 --- PooyanDeterministic\n",
      "187 of 256 --- PooyanNoFrameskip\n",
      "188 of 256 --- PrivateEye\n",
      "189 of 256 --- PrivateEyeDeterministic\n",
      "190 of 256 --- PrivateEyeNoFrameskip\n",
      "191 of 256 --- Pusher\n",
      "192 of 256 --- Qbert\n",
      "193 of 256 --- QbertDeterministic\n",
      "194 of 256 --- QbertNoFrameskip\n",
      "195 of 256 --- Reacher\n",
      "196 of 256 --- RepeatCopy\n",
      "197 of 256 --- Reverse\n",
      "198 of 256 --- ReversedAddition\n",
      "199 of 256 --- ReversedAddition3\n",
      "200 of 256 --- Riverraid\n",
      "201 of 256 --- RiverraidDeterministic\n",
      "202 of 256 --- RiverraidNoFrameskip\n",
      "203 of 256 --- RoadRunner\n",
      "204 of 256 --- RoadRunnerDeterministic\n",
      "205 of 256 --- RoadRunnerNoFrameskip\n",
      "206 of 256 --- Robotank\n",
      "207 of 256 --- RobotankDeterministic\n",
      "208 of 256 --- RobotankNoFrameskip\n",
      "209 of 256 --- Roulette\n",
      "210 of 256 --- Seaquest\n",
      "211 of 256 --- SeaquestDeterministic\n",
      "212 of 256 --- SeaquestNoFrameskip\n",
      "213 of 256 --- Skiing\n",
      "214 of 256 --- SkiingDeterministic\n",
      "215 of 256 --- SkiingNoFrameskip\n",
      "216 of 256 --- Solaris\n",
      "217 of 256 --- SolarisDeterministic\n",
      "218 of 256 --- SolarisNoFrameskip\n",
      "219 of 256 --- SpaceInvaders\n",
      "220 of 256 --- SpaceInvadersDeterministic\n",
      "221 of 256 --- SpaceInvadersNoFrameskip\n",
      "222 of 256 --- StarGunner\n",
      "223 of 256 --- StarGunnerDeterministic\n",
      "224 of 256 --- StarGunnerNoFrameskip\n",
      "225 of 256 --- Striker\n",
      "226 of 256 --- Swimmer\n",
      "227 of 256 --- Taxi\n",
      "228 of 256 --- Tennis\n",
      "229 of 256 --- TennisDeterministic\n",
      "230 of 256 --- TennisNoFrameskip\n",
      "231 of 256 --- Thrower\n",
      "232 of 256 --- TimePilot\n",
      "233 of 256 --- TimePilotDeterministic\n",
      "234 of 256 --- TimePilotNoFrameskip\n",
      "235 of 256 --- Tutankham\n",
      "236 of 256 --- TutankhamDeterministic\n",
      "237 of 256 --- TutankhamNoFrameskip\n",
      "238 of 256 --- UpNDown\n",
      "239 of 256 --- UpNDownDeterministic\n",
      "240 of 256 --- UpNDownNoFrameskip\n",
      "241 of 256 --- Venture\n",
      "242 of 256 --- VentureDeterministic\n",
      "243 of 256 --- VentureNoFrameskip\n",
      "244 of 256 --- VideoPinball\n",
      "245 of 256 --- VideoPinballDeterministic\n",
      "246 of 256 --- VideoPinballNoFrameskip\n",
      "247 of 256 --- Walker2d\n",
      "248 of 256 --- WizardOfWor\n",
      "249 of 256 --- WizardOfWorDeterministic\n",
      "250 of 256 --- WizardOfWorNoFrameskip\n",
      "251 of 256 --- YarsRevenge\n",
      "252 of 256 --- YarsRevengeDeterministic\n",
      "253 of 256 --- YarsRevengeNoFrameskip\n",
      "254 of 256 --- Zaxxon\n",
      "255 of 256 --- ZaxxonDeterministic\n",
      "256 of 256 --- ZaxxonNoFrameskip\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/48989130\n",
    "gym_environments = np.unique([e.__repr__().replace('EnvSpec(', '').split('-')[0] \\\n",
    "                              for e in list(gym.envs.registry.all())])  # remove class name & version info (get base name)\n",
    "for idx, e in enumerate(gym_environments):\n",
    "    print(idx+1, 'of', len(gym_environments), '---', e)\n",
    "    # remove class name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Safe to say, `gym` has a lot of environments.\n",
    "\n",
    "The environment that we're going to sample is one that is posted on OpenAI's homepage: MountainCar. Without further adieu, let's run a gym. The goal is to push a minecart up a hill that can only be surmounted by utilizing momentum. See https://github.com/openai/gym/wiki/MountainCar-v0 for the rest of the explanation or just run the code below and see what I mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# https://gym.openai.com/\n",
    "env = gym.make('MountainCar-v0')\n",
    "observation = env.reset() # state_0\n",
    "for i in range(10000):\n",
    "    env.render()\n",
    "    action = env.action_space.sample() # action_i selected -- in this case it's randomly sampled \n",
    "    # https://github.com/openai/gym/wiki/MountainCar-v0 for actions int in [0,2] (int's correspond to something)\n",
    "    \n",
    "    observation, reward, done, info = env.step(action) \n",
    "    # action_i taken; get observation_i+1, reward_i+1, done_i+1, and a info dict for metadata\n",
    "    # done is True if goal achieved or game over; else False\n",
    "    # observation: (position [one dimensional -- just the x-axis], velocity [in that one dimension])\n",
    "    # ^ https://github.com/openai/gym/blob/1d31c12437e8bd7f466139a479705819fff8c111/gym/envs/classic_control/mountain_car.py#L57\n",
    "    \n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "        \n",
    "env.close()  # close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully this simple example conveys the \"easy-to-use\" and \"standardized\" -ness. All that we really have to do is specify an action selection function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(position, velocity):\n",
    "    # https://github.com/openai/gym/wiki/MountainCar-v0 for actions\n",
    "    push_left = 0\n",
    "    no_push = 1\n",
    "    push_right = 2\n",
    "    position_min = -1.2\n",
    "    position_max = 0.6\n",
    "    velocity_min = -0.07\n",
    "    velocity_max = 0.07\n",
    "    \n",
    "    if -0.9 <= position <= 0.0 and velocity <= 0:\n",
    "        return push_left\n",
    "    \n",
    "    else:\n",
    "        return push_right \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Achieved the objective!\n"
     ]
    }
   ],
   "source": [
    "# https://gym.openai.com/\n",
    "env = gym.make('MountainCar-v0')\n",
    "observation = env.reset()\n",
    "max_iter = 200\n",
    "for i in range(max_iter):\n",
    "    env.render()\n",
    "    action = select_action(position=observation[0], velocity=observation[1])\n",
    "    \n",
    "    observation, reward, done, info = env.step(action) \n",
    "    \n",
    "    if done and i < max_iter:\n",
    "        print('Achieved the objective!')\n",
    "        break\n",
    "    elif done: \n",
    "        print('Failed to achieve the objective! Restarting')\n",
    "        observation = env.reset()\n",
    "        break\n",
    "        \n",
    "env.close()  # close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, of course, it isn't all that impressive for a human to hard-code a solution to this problem. This problem/environment was really created to test the capabilities of control algorithms that don't know anything about mine carts or mountains or the laws of physics and so on. For now, though, I'm going to leave off here. Hopefully by now you at least know how to use `gym` at a *very* basic level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
